{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9rvlymMZdJg"
   },
   "source": [
    "# Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-bvUtJ_OLwQA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convenience shortcuts, needed because when numpy matrix multiplications result in 1x1 matrix\n",
    "# then it is output as scalar, which further matrix multiplications refuse to work with. This makes no sense.\n",
    "# It is impossible to write a clean code that would work with matrices regardless of their shape!\n",
    "\n",
    "def ext_kf(u,P,F,Q=0,d=None,H=None,R=None):\n",
    "  \"\"\"\n",
    "  One step of the extended Kalman filter. \n",
    "  If there is no data, only advance in time.\n",
    "  :param u:   the state vector, shape n\n",
    "  :param P:   the state covariance, shape (n,n)\n",
    "  :param Q:   the process model noise covariance, shape (n,n)\n",
    "  :param F:   the model function, maps vector u to vector F(u) and Jacobian J(u)\n",
    "  :param d:   data vector, shape (m)\n",
    "  :param H:   observation matrix, shape (m,n)\n",
    "  :param R:   data error covariance, shape (n,n)\n",
    "  :return ua: the analysis state vector, shape (n)\n",
    "  :return Pa: the analysis covariance matrix, shape (n,n)\n",
    "  \"\"\"\n",
    "  def d2(a):\n",
    "    return np.atleast_2d(a) # convert to at least 2d array\n",
    "\n",
    "  def d1(a):\n",
    "    return np.atleast_1d(a) # convert to at least 1d array\n",
    "\n",
    "  # forecast\n",
    "  uf, J  = F(u)          # advance the model state in time and get the Jacobian\n",
    "  uf = d1(uf)            # if scalar, make state a 1D array\n",
    "  P = d2(P)              # if scalar, make Jacobian as 2D array\n",
    "  Pf  = d2(J.T @ P) @ J + Q  # advance the state covariance Pf = J' * P * J + Q\n",
    "  # analysis\n",
    "  if d is None or not d.size :  # no data, no analysis\n",
    "    return uf, Pf\n",
    "  # K = P H' * inverse(H * P * H' + R) = (inverse(H * P * H' + R)*(H P))'\n",
    "  H = d2(H)\n",
    "  HP  = d2(H @ P)            # precompute a part used twice  \n",
    "  K   = d2(np.linalg.solve( d2(HP @ H.T) + R, HP)).T  # Kalman gain\n",
    "  # print('H',H)\n",
    "  # print('K',K)\n",
    "  res = d1(H @ d1(uf) - d)          # res = H*uf - d\n",
    "  ua = uf - K @ res # analysis mean uf - K*res\n",
    "  Pa = Pf - K @ d2(H @ P)        # analysis covariance\n",
    "  return ua, d2(Pa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9pD9grsAJMq"
   },
   "source": [
    "##  A basic exponential decay model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHGMoaVWao89"
   },
   "source": [
    "The model is defined by solving the differential equation on interval $\\left[\n",
    "t_{0},t_{1}\\right]  $,\n",
    "$$\n",
    "\\frac{dm}{dt}=\\frac{E-m(t)}{T},\\quad m(t_{0})=m_{0}.\n",
    "$$\n",
    "where the initial fuel moisture content $m_{0}=m\\left(  t_{0}\\right)  $ is the\n",
    "input, and $m_{1}=m(t_{1})$ is the output. The parameters of the model are\n",
    "fuel moisture equilibrium $E$, assumed constant over the interval $\\left[\n",
    "t_{0},t_{1}\\right]  $, the characteristic decay time $T$, and the length of\n",
    "the interval, $t_{1}-t_{0}$. \n",
    "\n",
    "We can build the general model by calling this simple model with different\n",
    "equilibria and time constants (drying, wetting, rain).\n",
    "\n",
    "Since $E$ is constant in time, the solution can be found\n",
    "analytically,\n",
    "$$\n",
    "m\\left(  t\\right)  =E+\\left(  m_{0}-E\\right)  e^{-t/T}%\n",
    "$$\n",
    "For convenience, we use $T_{1}=1/T$ instead of $T$, and the model becomes\n",
    "$$\n",
    "m_{1}=E+\\left(  m_{0}-E\\right)  e^{-\\left(  t_{1}-t_{0}\\right)  T_{1}}%\n",
    "$$\n",
    "In the extended Kalman filter, we will need the partial derivatives of $m_{1}$\n",
    "with respect to the input and the parameters. Compute\n",
    "$$\n",
    "\\frac{dm_{1}}{d_{m0}}=e^{-\\left(  t_{1}-t_{0}\\right)  T_{1}}\n",
    "$$\n",
    "$$\n",
    "\\frac{dm_{1}}{dE}=1-e^{-\\left(  t_{1}-t_{0}\\right)  T_{1}}\n",
    "$$\n",
    "$$\n",
    "\\frac{dm_{1}}{dT_{1}}=-\\left(  m_{0}-E\\right)  \\left(  t_{1}-t_{0}\\right)\n",
    "e^{-\\left(  t_{1}-t_{0}\\right)  T_{1}}\n",
    "$$\n",
    "At the moment, we need only ${dm_{1}}/{dm_{0}}$ but we put in the code all partials for possible use infuture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqcs0zEiAn0j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def model_decay(m0,E,partials=0,T1=0.1,tlen=1):\n",
    "  exp_t = np.exp(-tlen*T1)                  # compute this subexpression only once\n",
    "  m1 = E + (m0 - E)*exp_t                   # the solution at end\n",
    "  if partials==0:\n",
    "    return m1\n",
    "  dm1_dm0 = exp_t\n",
    "  if partials==1:\n",
    "    return m1, np.array([dm1_dm0])          # return value and Jacobian\n",
    "  dm1_dE = 1 - exp_t                        # partial derivative dm1 / dE\n",
    "  dm1_dT1 = -(m0 - E)*tlen*exp_t            # partial derivative dm1 / dT1\n",
    "  return m1, dm1_dm0, dm1_dE, dm1_dT1       # return value and all partial derivatives wrt m1 and parameters\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLPJT3FcA2a7"
   },
   "source": [
    "## Kalman filter demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBv10PTiChhm"
   },
   "source": [
    "### Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_pz-wXnCMnP"
   },
   "outputs": [],
   "source": [
    "import numpy as np, random\n",
    "days = 10       \n",
    "hours = days*24\n",
    "day = np.array(range(2*hours))/24.\n",
    "\n",
    "# artificial equilibrium data\n",
    "E = np.power(np.sin(np.pi*day),4) # diurnal curve\n",
    "E = 0.05+0.25*E\n",
    "E # scale \n",
    "# FMC free run\n",
    "m_f = np.zeros(2*hours)\n",
    "m_f[0] = 0.1         # initial FMC\n",
    "for t in range(2*hours-1):\n",
    "  m_f[t+1] = max(0.,model_decay(m_f[t],E[t])  + random.gauss(0,0.005) )\n",
    "data = m_f + np.random.normal(loc=0,scale=0.02,size=2*hours)    \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(day[0:2*hours],E[0:2*hours],linestyle='--',c='r',label='Equilibrium')\n",
    "plt.plot(day[0:2*hours],m_f[0:2*hours],linestyle='-',c='k',label='10-h fuel truth')\n",
    "plt.scatter(day[0:hours],data[0:hours],c='b',label='10-h fuel data')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-3WLAEpD2yJ"
   },
   "source": [
    "### Run Kalman filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used the same code for model and for the truth. Now what if the model is wrong - different from nature? That is always so in reality. Suppose,for example, that the equilibrium $E$ in the model and in the truth does not agree, the model thinks that $E$ is by $\\Delta E$ too high:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-CjONZkD18n"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def kf_example(DeltaE):\n",
    "  m = np.zeros(2*hours)\n",
    "  m[0]=0.1             # background state  \n",
    "  P = np.zeros(2*hours)\n",
    "  P[0] = 0.03 # background state variance\n",
    "  Q = np.array([0.02]) # process noise variance\n",
    "  H = np.array([1.])   # all observed\n",
    "  R = np.array([0.02]) # data variance\n",
    "\n",
    "  for t in range(hours):\n",
    "    # use lambda construction to pass additional arguments to the model \n",
    "    m[t+1],P[t+1] = ext_kf(m[t],P[t],lambda u: model_decay(u,E[t]+DeltaE,partials=1),Q,\n",
    "                    d=data[t],H=H,R=R)\n",
    "  for t in range(hours,2*hours - 1):\n",
    "    m[t+1],P[t+1] = ext_kf(m[t],P[t],lambda u: model_decay(u,E[t]+DeltaE,partials=1))\n",
    "  \n",
    "  %matplotlib inline\n",
    "  plt.figure() # new figure\n",
    "  plt.plot(day,P,linestyle='-',c='b',label='Estimated state variance P')\n",
    "    \n",
    "  %matplotlib inline\n",
    "  plt.figure(figsize=(16,4))\n",
    "  plt.plot(day,E,linestyle='--',c='r',label='Equilibrium')\n",
    "  plt.plot(day,m_f,linestyle='-',c='k',label='10-h fuel truth')\n",
    "  plt.scatter(day[0:hours],data[0:hours],c='b',label='10-h fuel data')\n",
    "  plt.plot(day,m,linestyle='-',c='r',label='filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DeltaE = 0.0          # bias\n",
    "kf_example(DeltaE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqyB2Yz3uCsD"
   },
   "source": [
    "We have recovered the fuel moisture from data with random noise - we **filtered** the noise out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose that the model and the truth are not the same. That is always the case in reality. \n",
    "Consider a simple case when the model thinks that the equilibrium $E$ is too high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeltaE = 0.05\n",
    "kf_example(DeltaE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQeF7J8T4j2i"
   },
   "source": [
    "We have found a good estimate of the state $m$. Also, the estimated state variance $P$ converges with time - we have *learned* the variance that balances the noise. But for forecasting fuel moisture, we need to continue the fuel moisture model into the future, and we can't have any measurements from future. We only have the equilibrium from weather forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uXVJj9koGF2"
   },
   "source": [
    "First, make the API available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5I8Hz20nXMQ"
   },
   "outputs": [],
   "source": [
    "!pip install MesoPy\n",
    "from MesoPy import Meso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1HVOT-soL_e"
   },
   "source": [
    " Get all stations with fuel moisture data in the box within one hour: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBp6J9gRc83D"
   },
   "outputs": [],
   "source": [
    "# Take the first station in the boulding box that has data between time_start and time_s2.\n",
    "# Then retrieve data for that station between time_start and time_end\n",
    "time_start = \"201806010800\"  # June 1 2018 08:00 in format yyyymmddHHMM \n",
    "time_s2   = \"201806010900\"  # June 1 2018 09:00 in format yyyymmddHHMM \n",
    "time_end   = \"201806200900\"  # Nov 1 2018 09:00 in format yyyymmddHHMM \n",
    "bounding_box = \"-115, 38, -110, 40\"  # min longtitude, latitude\n",
    "meso_token=\"b40cb52cbdef43ef81329b84e8fd874f\"       # you should get your own if you do more of this\n",
    "m = Meso(meso_token)                                     # create a Meso object\n",
    "meso_obss = m.timeseries(time_start, time_s2, bbox=bounding_box, showemptystations = '0', vars='fuel_moisture')   # ask the object for data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGv5pfNSrLce"
   },
   "source": [
    "Print the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HE-r6GlnjWY7"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "#print(json.dumps(meso_obss, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spCF7VdhvIIn"
   },
   "source": [
    "Pick one station "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPbrsJMtkiKx"
   },
   "outputs": [],
   "source": [
    "station=meso_obss['STATION'][0]\n",
    "#print(json.dumps(station, indent=4))\n",
    "lon,lat = (float(station['LONGITUDE']),float(station['LATITUDE']))\n",
    "print(station['NAME'],'station',station['STID'],'at',lon,lat)\n",
    "e = 0.01\n",
    "bb = '%s, %s, %s, %s' % (lon - e, lat - e, lon + e, lat + e)\n",
    "print('bounding box',bb)\n",
    "meso_ts = m.timeseries(time_start, time_end, bbox=bb, showemptystations = '0', vars='fuel_moisture')   # ask the object for data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bXopS3btyz0"
   },
   "outputs": [],
   "source": [
    "# process the data retrieved for this statin\n",
    "# print(json.dumps(meso_ts['STATION'][0], indent=4))\n",
    "from datetime import datetime, timedelta, time\n",
    "import pytz\n",
    "time_str  = meso_ts['STATION'][0]['OBSERVATIONS']['date_time']\n",
    "obs_time = [datetime.strptime(t, '%Y-%m-%dT%H:%M:%SZ').replace(tzinfo=pytz.UTC) for t in time_str]\n",
    "obs_data = np.array(meso_ts['STATION'][0]['OBSERVATIONS'][\"fuel_moisture_set_1\"])\n",
    "# display the data retrieved\n",
    "for o_time,o_data in zip (obs_time,obs_data):\n",
    "    print(o_time,o_data)\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(obs_data,linestyle='-',c='k',label='10-h fuel data')\n",
    "plt.title(station['STID'] + ' 10 h fuel moisture data' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgKsHsDstoxg"
   },
   "outputs": [],
   "source": [
    "# retrieve RTMA data for this time period and compute equilibrium fuel moisture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1633285232385,
     "user": {
      "displayName": "WRF Fire",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09833348162306222387"
     },
     "user_tz": 360
    },
    "id": "4Vy5r9Ug2iBO"
   },
   "outputs": [],
   "source": [
    "import numpy as np, os\n",
    "if not [int(i) for i in np.__version__.split('.')] >= [1,20,1]: # check numpy version\n",
    "  print('Upgrading numpy and stopping RUNTIME! When the notebook completes, please run again.')\n",
    "  ! pip install --upgrade numpy    # suggested by Efosa, see also https://github.com/jswhit/pygrib/issues/192\n",
    "  os.kill(os.getpid(), 9)          # kill the runtime, need to run again from the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pY4hPeATK9wZ"
   },
   "source": [
    "Installing dependences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3061,
     "status": "ok",
     "timestamp": 1633285235583,
     "user": {
      "displayName": "WRF Fire",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09833348162306222387"
     },
     "user_tz": 360
    },
    "id": "TwqwYQrBLDck",
    "outputId": "2eb14e59-9297-4dc1-c328-4d3527297eb6"
   },
   "outputs": [],
   "source": [
    "! pip install pygrib   \n",
    "! wget --no-clobber https://raw.githubusercontent.com/openwfm/wrfxpy/master/src/ingest/grib_file.py\n",
    "from grib_file import GribFile     # Martin's utility layer on top of  pygrib,from wrfxpy\n",
    "import numpy as np, os # imported before, just in case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ-uJI2sy6I3"
   },
   "source": [
    "Create a function to transfer RTMA file in GRIP2 format from the stash. The function returns zero if the file transfer succeeded. If the file is not available, it returns a nonzero value. Note: if needed, maybe in future add more sophisticated checks, check the return code of wget and if the file size is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1633285235584,
     "user": {
      "displayName": "WRF Fire",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09833348162306222387"
     },
     "user_tz": 360
    },
    "id": "mxZABVDxt0gd"
   },
   "outputs": [],
   "source": [
    "import subprocess,os\n",
    "def load_rtma(path,file,reload=0):\n",
    "  url='http://math.ucdenver.edu/~jmandel/rtma/' + path \n",
    "  if os.path.exists(file):\n",
    "    if reload:\n",
    "      print(file + ' already exists, removing')\n",
    "      os.remove(file)\n",
    "    else:\n",
    "      print(file + ' already exists, exiting')\n",
    "      # add checking size here\n",
    "      return 0\n",
    "  try:\n",
    "    ret = subprocess.check_output(['wget','--no-clobber','--output-document='+ file, url,],stderr=subprocess.STDOUT).decode() # execute command from python strings\n",
    "    if os.path.exists(file):\n",
    "      print('loaded ' + url + ' as ' + file)\n",
    "      return 0\n",
    "    else: \n",
    "      print('file transfer completed, but the file is missing? ' + url)  \n",
    "      return 1\n",
    "  except:\n",
    "    print('file transfer failed: ' + url)\n",
    "    return 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THI6gElyHOOc"
   },
   "source": [
    "Get the files we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import intergrid\n",
    "def rtma_grib(t,var):\n",
    "    tpath = '%4i%02i%02i/%02i' % (t.year, t.month, t.day, t.hour)\n",
    "    tstr  = '%4i%02i%02i%02i_' % (t.year, t.month, t.day, t.hour)\n",
    "    gribfile = tstr + var + '.grib'\n",
    "    if load_rtma(tpath + '/' + var + '.grib',gribfile):\n",
    "        print('cannot load file')\n",
    "    gf=GribFile(gribfile)\n",
    "    v = np.array(gf.values())\n",
    "    print('loaded array shape ',v.shape)\n",
    "    return gf[1]   # grib message\n",
    "for t in pd.date_range(start=obs_time[0].replace(minute=0),end=obs_time[-1],freq='1H'):\n",
    "    print(t)\n",
    "    gf = rtma_grib(t,'temp')   # temperature\n",
    "    gf = rtma_grib(t,'td')     # dew point\n",
    "    gf = rtma_grib(t,'precipa')# rain    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1633285236049,
     "user": {
      "displayName": "WRF Fire",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09833348162306222387"
     },
     "user_tz": 360
    },
    "id": "Dwbt4UXfro5x",
    "outputId": "99320267-88f4-4a7a-ba4f-944ccfccde1b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i in pd.time_range\n",
    "year, month, day, hour, variable  = (2018, 5, 18, 00, 'temp')  # year, month, day, hour, variable\n",
    "file = variable + '.grib'\n",
    "path = '%4i%02i%02i/%02i/%s' % (year, month, day, hour, file)\n",
    "\n",
    "ret=load_rtma(path,file)   # load the file; ret is the return value that can be tested in application\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yRu_7WvHc6P"
   },
   "source": [
    "Trying to read the file and a basic sanity check if the values make sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 978,
     "status": "ok",
     "timestamp": 1633285237026,
     "user": {
      "displayName": "WRF Fire",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09833348162306222387"
     },
     "user_tz": 360
    },
    "id": "0uSEAB1dZc7P",
    "outputId": "ad890053-1452-49c2-e955-966973932827"
   },
   "outputs": [],
   "source": [
    "gf = GribFile(file)[1]        # grib file consists of \"messages\" (basically, variables), rtma files have only one\n",
    "lats, lons = gf.latlons()     # grid of geo coodinates (computed), should be the same for all rtma files here\n",
    "lats = np.array(lats)         # tuple to numpy array\n",
    "lons = np.array(lons)         # tuple to numpy array\n",
    "temp = np.array(gf.values())  # the actual variable values (here, T at 2m in K)\n",
    "\n",
    "print('min lats %s max %s' % (np.amin(lats),np.amax(lats)))\n",
    "print('shape',lats.shape)\n",
    "print('min lons %s max %s' % (np.amin(lons),np.amax(lons)))\n",
    "print('shape',lons.shape)\n",
    "print('min temp %s max %s' % (np.amin(temp),np.amax(temp)))\n",
    "print('shape',temp.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-u_piG3uICUA"
   },
   "source": [
    "One special grib file with the terrain height is stored at the root of the stash. This file is a part of the RTMA dataset but no need to download and store every hour, the data should never change. Trying to read it and doing a sanity check. Also,checking if the grid coordinages in this file are the same as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1452,
     "status": "ok",
     "timestamp": 1633285238477,
     "user": {
      "displayName": "WRF Fire",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09833348162306222387"
     },
     "user_tz": 360
    },
    "id": "JZlX8BVl4HRB",
    "outputId": "77812006-9b98-4936-961c-8672822abfdc"
   },
   "outputs": [],
   "source": [
    "hf='ds.terrainh.bin'   # terrain height, same in rtma at all times\n",
    "load_rtma(hf,hf)\n",
    "gf = GribFile(hf)[1] \n",
    "hgt = np.array(gf.values()) # height in m\n",
    "print('min height %s max %s' % (np.amin(hgt),np.amax(hgt)))\n",
    "print('shape',hgt.shape)\n",
    "hlats, hlons = gf.latlons()     # grid of geo coodinates (computed), should be the same for all rtma files here\n",
    "hlats = np.array(hlats)         # tuple to numpy array\n",
    "hlons = np.array(hlons) \n",
    "print('difference in lats %s lons %s' % (np.amax(np.absolute(lats-hlats)), np.amax(np.absolute(lons-hlons))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qkkuse_UuiMH"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jivOYEhiXMi5"
   },
   "source": [
    "## Model with augmented state\n",
    "In reality, the equilibrium moisture $E$ computed from atmospheric conditions\n",
    "generally does not agree with the data. We want to add a correction $\\Delta\n",
    "E$ to $E$ constant in time, and identify the new parameter $\\Delta E$ from data. \n",
    "Because the Kalman filter identifies state, add the parameter to the state.\n",
    "Define augmented state $u=\\left[\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "m\\\\\n",
    "\\Delta E\n",
    "\\end{array}\n",
    "\\right]  .$ Since $\\Delta E$ is constant in time, it satisfies the\n",
    "differential equation $\\frac{d\\Delta E}{dt}=0.$ So, we want to estimate the\n",
    "state $u$ governed by the\n",
    "$$\n",
    "\\frac{d}{dt}\\left[\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "m\\\\\n",
    "\\Delta E\n",
    "\\end{array}\n",
    "\\right]  =\\left[\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "\\frac{E+\\Delta E-m(t)}{T}\\\\\n",
    "0\n",
    "\\end{array}\n",
    "\\right]  ,\n",
    "$$\n",
    "which we write as $\\frac{du}{dt}=F(u),$ where\n",
    "$$\n",
    "F(u)=\\left[\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "F_{1}\\left(  u\\right)  \\\\\n",
    "F_{2}\\left(  u\\right)\n",
    "\\end{array}\n",
    "\\right]  =F\\left(  \\left[\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "m\\\\\n",
    "\\Delta E\n",
    "\\end{array}\n",
    "\\right]  \\right)  =\\left[\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "\\left(  E+\\Delta E-m(t)\\right)  T_{1}\\\\\n",
    "0\n",
    "\\end{array}\n",
    "\\right]  ,\\quad T_{1}=\\frac{1}{T}.\n",
    "$$\n",
    "The Jacobian of $F$ is\n",
    "$$\n",
    "\\left[\n",
    "\\begin{array}\n",
    "[c]{cc}\n",
    "\\frac{\\partial F_{1}}{\\partial u_{1}} & \\frac{\\partial F_{1}}{\\partial u_{2}\n",
    "}\\\\\n",
    "\\frac{\\partial F_{2}}{\\partial u_{1}} & \\frac{\\partial F_{2}}{\\partial u_{2}}\n",
    "\\end{array}\n",
    "\\right]  =\\left[\n",
    "\\begin{array}\n",
    "[c]{cc}\n",
    "\\frac{\\partial m_{1}}{\\partial m_{0}} & \\frac{\\partial m_{1}}{\\partial E}\\\\\n",
    "\\frac{\\partial\\Delta E}{\\partial m_{0}} & \\frac{\\partial\\Delta E}\n",
    "{\\partial\\Delta E}\n",
    "\\end{array}\n",
    "\\right]  =\\left[\n",
    "\\begin{array}\n",
    "[c]{cc}\n",
    "\\frac{\\partial m_{1}}{\\partial m_{0}} & \\frac{\\partial m_{1}}{\\partial E}\\\\\n",
    "0 & 1\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "Here is a function that implements the augmented model $F$. The input is\n",
    "$u_{0}$. The output is $u_{1}$ and the Jacobian $du_{1}/du_{0}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHtAaGp9WSHT"
   },
   "outputs": [],
   "source": [
    "def model_augmented(u0,E,T1,tlen=1):\n",
    "  # state u is the vector [m,dE] with dE correction to equilibrium\n",
    "  m0 = u0[0]  # decompose u0\n",
    "  dE = u0[1]\n",
    "  m1, dm1_dm0, dm1_dE, dm1_dT1  = model_decay(m0,E + dE,T1,tlen=tlen)\n",
    "  u1 = np.array([m1,dE])\n",
    "  J = np.array([dm1_dm0, dm1_dE],\n",
    "               [0.     ,     1.])\n",
    "  return m0, J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SuVNg8TsW4d"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1No3g6HyAEh_"
   },
   "outputs": [],
   "source": [
    "u = np.zeros((2,2*hours)\n",
    "u[:,0]=[0.1,0.1]             # background state  \n",
    "P = np.zeros(2,2,2*hours)\n",
    "P[:,:,0] = np.array([[0.03, 0.],\n",
    "                  [0.,    0.03]]) # background state covariance\n",
    "Q = np.array([[0.03, 0.],\n",
    "            [0,    0.03]]) # process noise covariance\n",
    "H = np.array([[1., 0.],\n",
    "             [0.,  .0]])   # first component observed\n",
    "R = np.array([0.02]) # data variance\n",
    "\n",
    "DeltaE = 0.05          # bias\n",
    "for t in range(hours):\n",
    "  # use lambda construction to pass additional arguments to the model \n",
    "  u[:,t+1],P[:,:,t+1] = ext_kf(m[:,t],d2(P[:,:,t]),lambda u: model_decay(u,E[t]+DeltaE,partials=1),Q,\n",
    "                    d=data[t],H=H,R=R)\n",
    "for t in range(hours,2*hours - 1):\n",
    "  u[:,t+1],P[:,:,t+1] = ext_kf(m[t],d2(P[t]),lambda u: model_decay(u,E[t]+DeltaE,partials=1))\n",
    "  \n",
    "    \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(day,E,linestyle='--',c='r',label='Equilibrium')\n",
    "plt.plot(day,m_f,linestyle='-',c='k',label='10-h fuel truth')\n",
    "plt.scatter(day[0:hours],data[0:hours],c='b',label='10-h fuel data')\n",
    "plt.plot(day,m,linestyle='-',c='r',label='filtered')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESJQ8dWiiork"
   },
   "outputs": [],
   "source": [
    "DeltaE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJDcq4QvNhJI"
   },
   "outputs": [],
   "source": [
    "d=np.array([])\n",
    "if d:\n",
    "  print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4_pVyy_IOHm"
   },
   "outputs": [],
   "source": [
    "for d in range(24):\n",
    "  print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8tMN3qOx3IP"
   },
   "source": [
    "# With real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IAGpfAiFtRu"
   },
   "outputs": [],
   "source": [
    "! pip install intergrid\n",
    "from intergrid.intergrid import Intergrid  # docs https://pypi.org/project/intergrid/\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "start_date = date(2018,5,19)\n",
    "end_date = date(2020,6,1)\n",
    "for d in pd.date_range(start_date,end_date,freq=\"1h\"):\n",
    "    path = d.strftime(\"%Y%m%d/%H\")\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQhxXLtbC5mc"
   },
   "source": [
    "#Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IavCNH4AC23l"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([1.])\n",
    "b = np.array([2.])\n",
    "c  = a @ b\n",
    "print('a',a)\n",
    "print('b',b)\n",
    "print('c=a@b',c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uvsbbv2XZ2Hd"
   },
   "source": [
    "# Testers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsOqvQk6ZXZV"
   },
   "outputs": [],
   "source": [
    "# a basic ext_kf test\n",
    "import numpy as np\n",
    "u = [1,\n",
    "     2]\n",
    "P = [[2 , -1],\n",
    "    [-1 , 2]]\n",
    "A = [ [1 ,2],\n",
    "      [3 ,4]]\n",
    "u = np.array(u)      \n",
    "Q = np.array([[1,0],[0,1]])\n",
    "A = np.array(A)\n",
    "def fun(u):\n",
    "  return A @ u, A\n",
    "F = lambda u: fun(u)\n",
    "H = [[1, 0],\n",
    "     [0, 1]]\n",
    "d = [2,\n",
    "    3]\n",
    "R = [[2, 0],\n",
    "    [0, 2]]\n",
    "H = np.array(H)      \n",
    "d = np.array(d)\n",
    "R = np.array(R)\n",
    "ua,Pa = ext_kf(u,P,F,Q)\n",
    "print('ua=',ua)\n",
    "print('Pa=',Pa)\n",
    "ua,Pa = ext_kf(u,P,F,Q,d,H,R)\n",
    "print('ua=',ua)\n",
    "print('Pa=',Pa)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jivOYEhiXMi5",
    "Uvsbbv2XZ2Hd"
   ],
   "name": "fmda.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

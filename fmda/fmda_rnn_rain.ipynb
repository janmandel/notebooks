{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7291842-a72d-4c4e-9312-6c0c31df18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from MesoPy import Meso\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "# Local modules for handling data and running moisture models\n",
    "import data_funcs as datf\n",
    "from data_funcs import format_precip, fixnan\n",
    "import moisture_models as mod\n",
    "\n",
    "meso_token=\"4192c18707b848299783d59a9317c6e1\"\n",
    "m=Meso(meso_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d299dea-9c39-4410-a4a5-a7f72d23ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean squared error\n",
    "def mse(a, b):\n",
    "    return ((a - b)**2).mean()\n",
    "# Calculate mean absolute error\n",
    "def mape(a, b):\n",
    "    return ((a - b).__abs__()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d3b14a-20e8-4e4e-802f-88404d151991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vprint(*args):\n",
    "    if verbose: \n",
    "        for s in args[:(len(args)-1)]:\n",
    "            print(s, end=' ')\n",
    "        print(args[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f972c-9a02-4550-8d82-1b9cf69d7e9c",
   "metadata": {},
   "source": [
    "## Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6236755-11e7-4b31-bf50-ffedb6077795",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = \"201806010800\"\n",
    "hours = 1200 # total simulation time\n",
    "time_end = datetime.strptime(time_start, \"%Y%m%d%H%M\")+timedelta(hours = hours+1) # end time, plus a buffer to control for time shift\n",
    "time_end = str(int(time_end.strftime(\"%Y%m%d%H%M\")))\n",
    "h2 = 300 # training period\n",
    "train_hrs = np.arange(0, h2) # training time\n",
    "test_hrs = np.arange(h2, hours) # forecast time\n",
    "\n",
    "print('Time Parameters:')\n",
    "print('-'*50)\n",
    "print('Time Start:', datetime.strptime(time_start, \"%Y%m%d%H%M\").strftime(\"%Y/%M/%d %H:%M\"))\n",
    "print('Time End:', datetime.strptime(time_end, \"%Y%m%d%H%M\").strftime(\"%Y/%M/%d %H:%M\"))\n",
    "print('Total Runtime:', hours, 'hours')\n",
    "print('Training Time:', h2, 'hours')\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8320fb68-771e-4441-8849-e5bdec432bd1",
   "metadata": {},
   "source": [
    "## Retrieve RAWS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4760ae44-d063-4543-b751-631a62bc9c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23241817-80d7-49b5-88c4-9803441bdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_raws(stn, fixnames = True):\n",
    "    raws_dat = stn['OBSERVATIONS']\n",
    "    \n",
    "    # Convert to Numpy arrays, check data type for floats\n",
    "    for key in [*stn['OBSERVATIONS'].keys()]:\n",
    "        if type(stn['OBSERVATIONS'][key][0]) is float:\n",
    "            raws_dat[key] = np.array(stn['OBSERVATIONS'][key], dtype = 'float64')\n",
    "        else:\n",
    "            raws_dat[key] = np.array(stn['OBSERVATIONS'][key])\n",
    "    \n",
    "    # Transform Data\n",
    "    raws_dat['air_temp_set_1'] = raws_dat['air_temp_set_1'] + 273.15 ## convert C to K\n",
    "    if 'precip_accum_set_1' in raws_dat.keys():\n",
    "        raws_dat['precip_accum_set_1'] = format_precip(raws_dat['precip_accum_set_1']) ## format precip data, accumulated to hourly\n",
    "    \n",
    "    \n",
    "    # Calculate Equilibrium Temps\n",
    "    raws_dat['Ed'] = 0.924*raws_dat['relative_humidity_set_1']**0.679 + 0.000499*np.exp(0.1*raws_dat['relative_humidity_set_1']) + 0.18*(21.1 + 273.15 - raws_dat['air_temp_set_1'])*(1 - np.exp(-0.115*raws_dat['relative_humidity_set_1']))\n",
    "    raws_dat['Ew'] = 0.618*raws_dat['relative_humidity_set_1']**0.753 + 0.000454*np.exp(0.1*raws_dat['relative_humidity_set_1']) + 0.18*(21.1 + 273.15 - raws_dat['air_temp_set_1'])*(1 - np.exp(-0.115*raws_dat['relative_humidity_set_1']))\n",
    "    \n",
    "    # Fix nan values\n",
    "    for key in [*raws_dat.keys()]:\n",
    "        if type(raws_dat[key][0]) is float:\n",
    "            raws_dat[key] = fixnan(raws_dat[key], 2)\n",
    "    \n",
    "    # Simplify names \n",
    "    if fixnames:\n",
    "        var_mapping = {\n",
    "            'date_time': 'time', 'precip_accum': 'rain', \n",
    "            'fuel_moisture': 'fm', 'relative_humidity': 'rh',\n",
    "            'air_temp': 'temp', 'Ed': 'Ed', 'Ew': 'Ew'\n",
    "            }\n",
    "        old_keys = [*raws_dat.keys()]\n",
    "        old_keys = [k.replace(\"_set_1\", \"\") for k in old_keys]\n",
    "        new_keys = []\n",
    "        for key in old_keys:\n",
    "            new_keys.append(var_mapping.get(key, key))\n",
    "        old_keys = [*raws_dat.keys()]\n",
    "        old_keys = [k.replace(\"_set_1\", \"\") for k in old_keys]\n",
    "        new_keys = []\n",
    "        for key in old_keys:\n",
    "            new_keys.append(var_mapping.get(key, key))\n",
    "        raws_dat2 = dict(zip(new_keys, list(raws_dat.values())))\n",
    "        return raws_dat2\n",
    "    \n",
    "    else: return raws_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2329fe-a45d-424a-a3d8-9bd1929798ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_raws(stid, raws_vars, time1, time2):\n",
    "    meso_ts = m.timeseries(time1, time2, \n",
    "                       stid=stid, vars=raws_vars)\n",
    "    station = meso_ts['STATION'][0]\n",
    "    \n",
    "    raws_dat = format_raws(station)\n",
    "    \n",
    "    return station, raws_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae1750-0656-4369-a114-2ccaa885ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_vars='air_temp,relative_humidity,precip_accum,fuel_moisture'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8616e-3f4d-4f56-8e52-f065e8d3d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "station, raws_dat = retrieve_raws(\"BKCU1\", raws_vars, time_start, time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d751525-58c9-4668-9755-f1aaeb34aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dat(stn, dat, val):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(dat[val],linestyle='-',c='k')\n",
    "    plt.title(stn['STID']+' '+ val)\n",
    "    plt.xlabel('Time (hours)') \n",
    "    plt.ylabel('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a6794-9c56-4a32-8699-15763465544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_dat(station, raws_dat, 'fm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e033c-5d16-44ec-9b58-4a55ff76d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Read:')\n",
    "print('-'*50)\n",
    "print('Station ID:', station['STID'])\n",
    "print('Lat / Lon:', station['LATITUDE'],', ',station['LONGITUDE'])\n",
    "if(station['QC_FLAGGED']): print('WARNING: station flagged for QC')\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45fcc1f-8394-418f-89ab-0cfbaa04d65f",
   "metadata": {},
   "source": [
    "## Retrieve RTMA Function\n",
    "\n",
    "<mark>Not needed?</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c42a886-ecff-4379-8a12-db9a77d64045",
   "metadata": {},
   "source": [
    "## Fit Augmented KF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8aa6b-a241-47e3-881f-6e75373f1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,Ec = mod.run_augmented_kf(raws_dat['fm'],raws_dat['Ed'],raws_dat['Ew'],raws_dat['rain'],h2,hours)  # extract from state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531fad3-1d6f-4738-a019-f587a7ab7139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_moisture(hmin,hmax):\n",
    "    print('training from 0 to',h2,'plot from',hmin,'to',hmax)\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(range(hmin,hmax),raws_dat['Ed'][hmin:hmax],linestyle='--',c='r',label='Drying Equilibrium (%)')\n",
    "    plt.plot(range(hmin,hmax),raws_dat['Ew'][hmin:hmax],linestyle='--',c='b',label='Wetting Equilibrium (%)')\n",
    "    plt.plot(range(hmin,hmax),Ec[hmin:hmax],linestyle='--',c='g',label='Equilibrium Correction (%)')\n",
    "    plt.plot(range(hmin,hmax),m[hmin:hmax],linestyle='-',c='k',label='filtered')\n",
    "    plt.plot(range(hmin,hmax),raws_dat['fm'][hmin:hmax],linestyle='-',c='b',label='RAWS data (%)')\n",
    "    plt.plot(range(hmin,hmax),raws_dat['rain'][hmin:hmax],linestyle='-',c='b',label='RTMA rain (mm/h)')\n",
    "    if hmin>=h2:\n",
    "        plt.plot(m[hmin:h2],linestyle='-',c='k',label='Filtered')\n",
    "    h1 = np.maximum(hmin,h2)\n",
    "    plt.plot(range(h1,hmax),m[h1:hmax],linestyle='-',c='r',label='Forecast (%)')\n",
    "    plt.title(station['STID'] +' Kalman filtering and forecast with augmented state, real data. Training 0:%i hmax' % h2)\n",
    "    plt.xlabel('Time (hours)') \n",
    "    plt.ylabel('Fuel moisture content (%)')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5388f2-1c21-4b4e-860f-a7ea7c7e2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_moisture(0, hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f0f20-b38f-4643-97cd-969914fca2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Error\n",
    "# print(mse(m, raws_dat['fm'][0:hours]))\n",
    "\n",
    "# Forecast Error\n",
    "print('Forecast MSE: ' + str(np.round(mse(m[h2:hours], raws_dat['fm'][h2:hours]), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a26c2-4a85-4c7e-b818-a1a2906dfb25",
   "metadata": {},
   "source": [
    "## Fit RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685893df-d47e-4b0a-be51-c357733a2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from scipy.interpolate import LinearNDInterpolator, interpn\n",
    "from scipy.optimize import root\n",
    "\n",
    "## Local Modules\n",
    "from moisture_models import create_RNN, create_RNN_2, staircase, seq2batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01143521-8222-4e69-9cde-7dc7c7c780e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a74f0-815c-4cb1-8ef4-9ff51ef31303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def staircase(x,y,timesteps,trainsteps,return_sequences=False, verbose = False):\n",
    "    # x [trainsteps+forecaststeps,features]    all inputs\n",
    "    # y [trainsteps,outputs]\n",
    "    # timesteps: split x and y into samples length timesteps, shifted by 1\n",
    "    # trainsteps: number of timesteps to use for training, no more than y.shape[0]\n",
    "    vprint('shape x = ',x.shape)\n",
    "    vprint('shape y = ',y.shape)\n",
    "    vprint('timesteps=',timesteps)\n",
    "    vprint('trainsteps=',trainsteps)\n",
    "    outputs = y.shape[1]\n",
    "    features = x.shape[1]\n",
    "    forecaststeps = x.shape[0]-trainsteps\n",
    "    samples = trainsteps-timesteps+1\n",
    "    vprint('staircase: samples=',samples,'timesteps=',timesteps,'features=',features)\n",
    "    x_train = np.empty([samples, timesteps, features])\n",
    "    vprint('return_sequences=',return_sequences)\n",
    "    if return_sequences:\n",
    "        vprint('returning all timesteps in a sample')\n",
    "        y_train = np.empty([samples, timesteps, outputs])  # all\n",
    "        for i in range(samples):\n",
    "            for k in range(timesteps):\n",
    "                for j in range(features):\n",
    "                    x_train[i,k,j] = x[i+k,j]\n",
    "                for j in range(outputs):\n",
    "                    y_train[i,k,j] = y[i+k,j]\n",
    "    else:\n",
    "        vprint('returning only the last timestep in a sample')\n",
    "    y_train = np.empty([samples, outputs])\n",
    "    for i in range(samples):\n",
    "        for j in range(features):\n",
    "            for k in range(timesteps):\n",
    "                x_train[i,k,j] = x[i+k,j]\n",
    "        for j in range(outputs):\n",
    "            y_train[i,j] = y[i+timesteps-1,j]\n",
    "\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3542320-7583-4eae-a70e-2315c58a48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_data(dat, scale = False, verbose = False):\n",
    "    Ew = dat['Ew']\n",
    "    Ed = dat['Ed']\n",
    "    rain = dat['rain']\n",
    "    fm = dat['fm']\n",
    "    temp = dat['temp']\n",
    "    \n",
    "    # Average Equilibrium\n",
    "    E = (Ed + Ew)/2\n",
    "    \n",
    "    # transform as 2D, (timesteps, features) and (timesteps, outputs)\n",
    "    Et = np.reshape(E,[E.shape[0],1])\n",
    "    datat = np.reshape(fm,[fm.shape[0],1])\n",
    "    \n",
    "    # Scale Data if required\n",
    "    scale=False\n",
    "    if scale:\n",
    "        scalerx = MinMaxScaler()\n",
    "        scalerx.fit(Et)\n",
    "        Et = scalerx.transform(Et)\n",
    "        scalery = MinMaxScaler()\n",
    "        scalery.fit(datat)\n",
    "        datat = scalery.transform(datat)\n",
    "        \n",
    "    # split data\n",
    "    x_train, y_train = staircase(Et,datat,timesteps=5,trainsteps=h2,\n",
    "                                 return_sequences=False, verbose = verbose)\n",
    "    vprint('x_train shape=',x_train.shape)\n",
    "    samples, timesteps, features = x_train.shape\n",
    "    vprint('y_train shape=',y_train.shape)\n",
    "\n",
    "    h0 = tf.convert_to_tensor(datat[:samples],dtype=tf.float32)\n",
    "    \n",
    "    # Set up return dictionary\n",
    "    \n",
    "    rnn_dat = {\n",
    "        'x_train': x_train,\n",
    "        'y_train': y_train,\n",
    "        'Et': Et,\n",
    "        'samples': samples,\n",
    "        'timesteps': timesteps,\n",
    "        'features': features,\n",
    "        'h0': h0\n",
    "    }\n",
    "    \n",
    "    return rnn_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5a394-c6f0-4af1-9890-37bf65ba0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "scale = False\n",
    "rnn_dat = create_rnn_data(raws_dat, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc767265-ccd3-4f7b-b020-18cbf8aa574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RNN_2(hidden_units, dense_units, activation, stateful=False, \n",
    "                 batch_shape=None, input_shape=None, dense_layers=1,\n",
    "                 rnn_layers=1,return_sequences=False,\n",
    "                 initial_state=None, verbose = True):\n",
    "    if stateful:\n",
    "        inputs = tf.keras.Input(batch_shape=batch_shape)\n",
    "    else:\n",
    "        inputs = tf.keras.Input(shape=input_shape)\n",
    "    # https://stackoverflow.com/questions/43448029/how-can-i-print-the-values-of-keras-tensors\n",
    "    # inputs2 = K.print_tensor(inputs, message='inputs = ')  # change allso inputs to inputs2 below, must be used\n",
    "    x = inputs\n",
    "    for i in range(rnn_layers):\n",
    "        x = tf.keras.layers.SimpleRNN(hidden_units,activation=activation[0],\n",
    "              stateful=stateful,return_sequences=return_sequences)(x\n",
    "              # ,initial_state=initial_state\n",
    "              )\n",
    "    # x = tf.keras.layers.Dense(hidden_units, activation=activation[1])(x)\n",
    "    for i in range(dense_layers):\n",
    "        x = tf.keras.layers.Dense(dense_units, activation=activation[1])(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6d196-2373-4d66-a482-b40ab68eeefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(rnn_dat, activation, hidden_units, dense_units, dense_layers, verbose = False):\n",
    "    \n",
    "    samples = rnn_dat['samples']\n",
    "    features = rnn_dat['features']\n",
    "    timesteps = rnn_dat['timesteps']\n",
    "    \n",
    "    model_fit=create_RNN_2(hidden_units=hidden_units, \n",
    "                        dense_units=dense_units, \n",
    "                        batch_shape=(samples,timesteps,features),\n",
    "                        stateful=True,\n",
    "                        return_sequences=False,\n",
    "                        # initial_state=h0,\n",
    "                        activation=activation,\n",
    "                        dense_layers=dense_layers)\n",
    "    \n",
    "    Et = rnn_dat['Et']\n",
    "    model_predict=create_RNN_2(hidden_units=hidden_units, dense_units=dense_units,  \n",
    "                            input_shape=(hours,features),stateful = False,\n",
    "                            return_sequences=True,\n",
    "                            activation=activation,dense_layers=dense_layers)\n",
    "\n",
    "    vprint('model_predict input shape',Et.shape,'output shape',model_predict(Et).shape)\n",
    "    if verbose: print(model_predict.summary())\n",
    "    \n",
    "    x_train = rnn_dat['x_train']\n",
    "    y_train = rnn_dat['y_train']\n",
    "\n",
    "    # fitting\n",
    "    DeltaE = 0\n",
    "    w_exact=  [np.array([[1.-np.exp(-0.1)]]), np.array([[np.exp(-0.1)]]), np.array([0.]),np.array([[1.0]]),np.array([-1.*DeltaE])]\n",
    "    w_initial=[np.array([[1.-np.exp(-0.1)]]), np.array([[np.exp(-0.1)]]), np.array([0.]),np.array([[1.0]]),np.array([-1.0])]\n",
    "    w=model_fit.get_weights()\n",
    "    for i in range(len(w)):\n",
    "        vprint('weight',i,'shape',w[i].shape,'ndim',w[i].ndim,'given',w_initial[i].shape)\n",
    "        for j in range(w[i].shape[0]):\n",
    "            if w[i].ndim==2:\n",
    "                for k in range(w[i].shape[1]):\n",
    "                    w[i][j][k]=w_initial[i][0][0]/w[i].shape[0]\n",
    "            else:\n",
    "                w[i][j]=w_initial[i][0]\n",
    "    model_fit.set_weights(w)\n",
    "    model_fit.fit(x_train, y_train, epochs=5000,batch_size=samples, verbose=0)\n",
    "    w_fitted=model_fit.get_weights()\n",
    "    for i in range(len(w)):\n",
    "        vprint('weight',i,' exact:',w_exact[i],':  initial:',w_initial[i],' fitted:',w_fitted[i])\n",
    "    \n",
    "    model_predict.set_weights(w_fitted)\n",
    "    \n",
    "    return model_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871821a9-bcd9-47db-9bd6-1933094ac137",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "model_predict = train_rnn(\n",
    "    rnn_dat,\n",
    "    activation=['linear','linear'],\n",
    "    hidden_units=3,\n",
    "    dense_units=1,\n",
    "    dense_layers=1,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c3954-6772-4810-9531-10a731ad3165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_predict(rnn_dat, scale = False, verbose = False):\n",
    "    scale = False\n",
    "    # model_predict.set_weights(w_fitted)\n",
    "    x_input=np.reshape(rnn_dat['Et'],(1, hours, 1))\n",
    "    y_output = model_predict.predict(x_input, verbose = verbose)\n",
    "    \n",
    "    vprint('x_input.shape=',x_input.shape,'y_output.shape=',y_output.shape)\n",
    "    \n",
    "    m = np.reshape(y_output,hours)\n",
    "    # print('weights=',w)\n",
    "    if scale:\n",
    "        vprint('scaling')\n",
    "        m = scalery.inverse_transform(m)\n",
    "    m = np.reshape(m,hours)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3ec60-292d-4526-a793-7d466f4ce9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 0\n",
    "m = rnn_predict(rnn_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc15fc-5d08-4df1-a4d5-4f0107171c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale = False\n",
    "# # model_predict.set_weights(w_fitted)\n",
    "# x_input=np.reshape(rnn_dat['Et'],(1, hours, 1))\n",
    "# y_output = model_predict.predict(x_input)\n",
    "# print('x_input.shape=',x_input.shape,'y_output.shape=',y_output.shape)\n",
    "# # print(shift)\n",
    "# m = np.reshape(y_output,hours)\n",
    "# # print('weights=',w)\n",
    "# if scale:\n",
    "#     print('scaling')\n",
    "#     m = scalery.inverse_transform(m)\n",
    "# m = np.reshape(m,hours)\n",
    "# hour=np.array(range(hours))\n",
    "title=\"RNN forecast\"\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(hour,rnn_dat['Et'][:,0],linestyle='--',c='r',label='E=Equilibrium data')\n",
    "# print(len(hour),len(m_f))\n",
    "plt.scatter(hour,raws_dat['fm'],c='b',label='data=10-h fuel data')\n",
    "if m is not None:\n",
    "    plt.plot(hour[:h2],m[:h2],linestyle='-',c='k',label='m=filtered')\n",
    "    plt.plot(hour[h2:hours],m[h2:hours],linestyle='-',c='r',label='m=forecast')\n",
    "plt.title(title) \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d06f6ee-2c05-4473-956c-ba490cf773d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Error\n",
    "print(mse(m, raws_dat['fm'][0:hours]))\n",
    "\n",
    "# Forecast Eror\n",
    "print(mse(m[h2:hours], raws_dat['fm'][h2:hours]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7253c4-0e4c-4076-8f2a-f661e057efd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
